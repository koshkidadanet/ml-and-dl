import numpy as np

def f(x):
    return 2/(1 + np.exp(-x)) - 1 #tahn

def df(x):
    return 0.5*(1 + x)*(1 - x) #произв tahn

W1 = np.array([[-0.2, 0.3, -0.4,0.5], [0.1, -0.3, -0.4,0.5]]) #веса для скрытого слоя рандомные
W2 = np.array([0.2, 0.3,0.5]) #веса для выходного слоя рандомные 

def go_forward(inp):
    sum = np.dot(W1, inp) #входные значения (входная сумма) для 2х внутренних нейронов
    out = np.array([f(x) for x in sum])#пропускаем сумму через ф-ию нормализации и получаем выходные значения
    out = np.append(out,1)
    sum = np.dot(W2, out)#входное значение (входная сумма) для выходного нейрона
    y = f(sum)#пропускаем сумму через ф-ию нормализации и получаем выходное значение
    return (y, out)

def train(epoch):
    global W2, W1
    lmd = 0.01          # шаг обучения
    N = 10000         # число итераций при обучении
    count = len(epoch)
    for k in range(N):
        x = epoch[np.random.randint(0, count)]  # случайных выбор входного сигнала из обучающей выборки
        #на вход в  go_forward подаем 3 входных значения
        y, out = go_forward(x[0:4])             # прямой проход по НС и вычисление выходных значений нейронов
        e = y - x[-1]                           # ошибка
        delta = e*df(y)                         # локальный градиент
        W2[0] = W2[0] - lmd * delta * out[0]    # корректировка веса первой связи
        W2[1] = W2[1] - lmd * delta * out[1]    # корректировка веса второй связи

        delta2 = W2*delta*df(out)               # вектор из 2-х величин локальных градиентов

        # корректировка связей первого слоя
        W1[0, :] = W1[0, :] - np.array(x[0:4]) * delta2[0] * lmd
        W1[1, :] = W1[1, :] - np.array(x[0:4]) * delta2[1] * lmd

# обучающая выборка (она же полная выборка)
'''epoch = [(-1, -1, -1, 1,-1),
         (-1, -1, 1, 1,1),
         (-1, 1, -1,1, -1),
         (-1, 1, 1, 1,1),
         (1, -1, -1, 1,-1),
         (1, -1, 1, 1,1),
         (1, 1, -1,1, -1),
         (1, 1, 1, 1,-1)]'''

epoch = [(-1, -1, -1, 1,-1),
         (-1, -1, 1, 1,1),
         (-1, 1, -1,1, -1),
         (-1, 1, 1, 1,1),
          (1, -1, 1, 1,1),
         (1, 1, -1,1, -1),
         (1, 1, 1, 1,-1)]

epoch1 = [(-1, -1, -1, 1,-1),
         (-1, -1, 1, 1,1),
         (-1, 1, -1,1, -1),
         (-1, 1, 1, 1,1),
         (1, -1, -1, 1,-1),
         (1, -1, 1, 1,1),
         (1, 1, -1,1, -1),
         (1, 1, 1, 1,-1)]


train(epoch)        # запуск обучения сети

# проверка полученных результатов
for x in epoch1:
    y, out = go_forward(x[0:4])
    print(f"Выходное значение НС: {y} => {x[-1]}")
